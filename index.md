---
layout: about 
---

### About Me üòÅ
I am a research assistant at Westlake University, supervised by Prof. [Huan Wang](https://scholar.google.com/citations?hl=zh-CN&user=0-On0y4AAAAJ). I received my M.S. degree in Computer Science from Chongqing Technology and Business University in 2025, under the supervision of Prof. [Huafeng Qin](https://scholar.google.com/citations?user=5jvXcJ0AAAAJ&hl=zh-CN). In 2022, I obtained my B.E. degree in Internet of Things Engineering from Pass Collage of Chongqing Technology and Business University.

**Research:** Currently, my research centers on **Efficient AI**, **Large Language Models**, and **Multi-modal Large Language Models**. Previously, my research focused on Data Augmentation and Biometric Identification.

**Interests:** In my spare time, I am an amateur photographer with a passion for capturing scenery and starry sky shots üåå. I use both digital cameras üì∑ and film cameras üéûÔ∏è for my photography.

Feel free to contact me for academic and research discussions. Please drop me an email at ``jinxin86@westlake.edu.cn``.

**<font color="#FF0000">I am actively seeking 26 Fall or 27 Spring PhD opportunities!</font>**

### News üí¨ 
<div style="max-height:500px;overflow-y:auto;padding:15px;background-color:#f9f9f9;border-radius:6px;">

  <ul>
    <li><b> <font color="#b80000">[2026.01]</font> </b> üéâ One paper on efficient mixup and preference tuning, <a href="https://arxiv.org/abs/2510.23479"> MergeMix</a> is accpted by <b>ICLR 2026</b>. </li>
    <li><b> <font color="#b80000">[2025.10]</font> </b> One paper on Mixup & MLLM, <a href="https://arxiv.org/abs/2510.23479"> MergeMix</a> is released on <b>arXiv</b>. </li>
    <li><b> <font color="#b80000">[2025.02]</font> </b> üéâ One paper on (M)LLM optimizers, <a href="https://huggingface.co/papers/2506.01049"> SGG</a> is accepted by <b>ACL 2025 main</b>, congrats to <font color="#2a7ce0">Siyuan Li, Juanxi Tian and Zedong Wang</font>. </li>
    <li><b> <font color="#b80000">[2025.02]</font> </b> Two co-author papers on eye moment identification, <a href="https://arxiv.org/abs/2401.04956"> EMMixFormer</a> and <a href="https://arxiv.org/abs/2409.14432"> EM-DARTS</a> are accepted by <b>IEEE TIM</b>, congrats to <font color="#2a7ce0">Hongyu Zhu</font>. </li>
    <li><b> <font color="#b80000">[2024.07]</font> </b> One paper on mixup data augmentation, <a href="https://arxiv.org/abs/2409.05202"> Survey</a>, is released on <b>arXiv</b>. </li>
    <li><b> <font color="#b80000">[2024.07]</font> </b> üéâ One paper on mixup data augmentation, <a href="https://arxiv.org/abs/2407.07805"> SUMix</a>, is accepted by <b>ECCV 2024</b>. </li>
    <li><b> <font color="#b80000">[2024.05]</font> </b> Co-author paper on vein identification, <a href="https://hsi2024.welcometohsi.org/"> GANet</a>, is accepted by <b>HSI 2024 (<font color="#FF0000">Oral</font>)</b>, congrats to <font color="#2a7ce0">Hongchao Liao</font>. </li>
    <li><b> <font color="#b80000">[2024.01]</font> </b> üéâ One paper on mixup data augmentation, <a href="https://arxiv.org/abs/2312.11954"> AdAutoMix</a>, is accepted by <b>ICLR 2024 (<font color="#FF0000">Spotlight</font>)</b>. </li>
  </ul>
</div>

### Experiences üìù
<!-- Chongqing Financial Institute -->
<table class="imgtable"><tr><td>
    <img src="./assets/img/CQFI.jpg" alt="" width="220px" />&nbsp;</td>
    <td style="text-align:left; vertical-align:top"><p>
        <font face="Lato">
          <b> Research Intern </b> | <a target="_blank" style="color:#2a7ce0">
            Chongqing Financial Institute
          </a>
        </font>
        <br>Time: July 2023 - Sept 2023. Advisor: <a href="https://scholar.google.com/citations?user=5jvXcJ0AAAAJ&hl=zh-CN">  Prof. Huafeng Qin</a>.<br>
        </p></td></tr>
</table>
          
<!-- Westlake University -->
<table class="imgtable"><tr><td>
    <img src="./assets/img/westlake_logo.png" alt="" width="220px" />&nbsp;</td>
    <td style="text-align:left; vertical-align:top"><p>
        <font face="Lato">
          <b> Research Intern </b> | <a target="_blank" style="color:#2a7ce0">
            Westlake University
          </a>
        </font>
        <br>Time: Mar. 2024 -- July 2025. Advisor: <a href="https://scholar.google.com/citations?user=Y-nyLGIAAAAJ&hl=zh-CN">  Prof. Stan Z. Li</a>.<br>
        </p></td></tr>
</table>

<!-- Westlake University -->
<table class="imgtable"><tr><td>
    <img src="./assets/img/westlake_logo.png" alt="" width="220px" />&nbsp;</td>
    <td style="text-align:left; vertical-align:top"><p>
        <font face="Lato">
          <b> Research Assistant </b> | <a target="_blank" style="color:#2a7ce0">
            Westlake University
          </a>
        </font>
        <br>Time: July. 2025 -- Present. Advisor: <a href="https://scholar.google.com/citations?user=0-On0y4AAAAJ&hl=en">  Prof. Huan Wang</a>.<br>
        </p></td></tr>
</table>

### Publications üìñ
**Selected Preprints:**

<table class="imgtable"><tr><td style="width:220px;height:130px">
    <img src="./assets/img/F4.png" alt="" />&nbsp;</td>
    <td align="left"><p>
        <font face="Lato"><b><a target="_blank" style="color:#2a7ce0">A Survey on Mixup Augmentations and Beyond</a></b></font><br>
        <b>Xin Jin</b><sup>*</sup>, Hongyu Zhu<sup>*</sup>, Siyuan Li<sup>*</sup>, Zedong Wang, Zicheng Liu, Juanxi Tian, Chang Yu, Huafeng Qin, and <i>IEEE Fellow</i> Stan. Z. Li<sup>‚Ä†</sup>
        <br><span class="pub-info"><i>arXiv, 2024</i> 
        [<a href="https://arxiv.org/abs/2409.05202" target="_blank" style="color:#2a7ce0">PDF</a>]
        [<a href="https://github.com/Westlake-AI/Awesome-Mixup" target="_blank" style="color:#2a7ce0">Awesome</a>]
        [<a href="./assets/bibtex/ArXiv_2024_MixupSurvey_bibtex" target="_blank" style="color:#2a7ce0">BibTeX</a>]</span>
</p></td></tr>
</table>

<table class="imgtable"><tr><td style="width:220px;height:130px">
    <img src="./assets/img/StarLKNet.jpg" alt="" />&nbsp;</td>
    <td align="left"><p>
        <font face="Lato"><b><a target="_blank" style="color:#2a7ce0">StarLKNet: Star Mixup with Large Kernel Networks for Palm Vein Identification</a></b></font><br>
        <b>Xin Jin</b><sup>*</sup>, Hongyu Zhu<sup>*</sup>, Mounim A. El-Yacoubi, Hongchao Liao, Huafeng Qin, and Yun Jiang<sup>‚Ä†</sup>  
        <br><span class="pub-info"><i>arXiv, 2024</i> 
        [<a href="https://arxiv.org/abs/2405.12721" target="_blank" style="color:#2a7ce0">PDF</a>]
        [<a href="./assets/bibtex/ArXiv_2024_StarLKNet_bibtex" target="_blank" style="color:#2a7ce0">BibTeX</a>]</span>
</p></td></tr>
</table>

**Conferences (*: Equal Contribution. ‚Ä†: Corresponding Author.):**

<!-- MergeMix: A Unified Augmentation Paradigm for Visual and Multi-Modal Understanding -->
<table class="imgtable"><tr><td class="table-row" style="width:220px;height:130px">
    <img src="./assets/img/MergeMix.png" alt="" />&nbsp;</td>
    <td align="left"><p>
        <font face="Lato"><b><a target="_blank" style="color:#2a7ce0">MergeMix: A Unified Augmentation Paradigm for Visual and Multi-Modal Understanding</a></b></font><br>
        <b>Xin Jin</b><sup>*</sup>, Siyuan Li<sup>*</sup>, Siyong Jian, Kai Yu, Huan Wang<sup>‚Ä†</sup>
        <br><span class="pub-info"><i><b>ICLR</b>, 2026</i> 
        [<a href="https://arxiv.org/abs/2510.23479" target="_blank" style="color:#2a7ce0">arXiv</a>]
        [<a href="https://huggingface.co/papers/2510.23479" target="_blank" style="color:#2a7ce0">HF DailyPapers</a>]
        [<a href="./assets/bibtex/ArXiv_2025_MergeMix_bibtex" target="_blank" style="color:#2a7ce0">BibTeX</a>]</span>
</p></td></tr>
</table>

<!-- Taming LLMs by Scaling Learning Rates with Gradient Grouping -->
<table class="imgtable"><tr><td class="table-row" style="width:220px;height:130px">
    <img src="./assets/img/SGG.png" alt="" />&nbsp;</td>
    <td align="left"><p>
        <font face="Lato"><b><a target="_blank" style="color:#2a7ce0">Taming LLMs by Scaling Learning Rates with Gradient Grouping</a></b></font><br>
        Siyuan Li<sup>*</sup>, Juanxi Tian<sup>*</sup>, Zedong Wang<sup>*</sup>,<b>Xin Jin</b>, Zicheng Liu<sup>‚Ä†</sup>, Wentao Zhang, Dan Xu
        <br><span class="pub-info"><i><b>ACL-main</b>, 2025</i> 
        [<a href="https://arxiv.org/abs/2506.01049" target="_blank" style="color:#2a7ce0">arXiv</a>]
        [<a href="https://huggingface.co/papers/2506.01049" target="_blank" style="color:#2a7ce0">HF DailyPapers Top-4</a>]
        [<a href="./assets/bibtex/ACL_2025_SGG_bibtex" target="_blank" style="color:#2a7ce0">BibTeX</a>]</span>
</p></td></tr>
</table>

<!-- SUMix: Mixup with Semantic and Uncertain Information -->
<table class="imgtable"><tr><td class="table-row" style="width:220px;height:130px">
    <img src="./assets/img/SUMix.png" alt="" />&nbsp;</td>
    <td align="left"><p>
        <font face="Lato"><b><a target="_blank" style="color:#2a7ce0">SUMix: Mixup with Semantic and Uncertain Information</a></b></font><br>
        Huafeng Qin<sup>*,‚Ä†</sup>, <b>Xin Jin</b><sup>*</sup>, Hongyu Zhu<sup>*</sup>, Hongchao Liao, Mounim A. El-Yacoubi, Xinbo Gao
        <br><span class="pub-info"><i><b>ECCV</b>, 2024</i> 
        [<a href="https://arxiv.org/abs/2407.07805" target="_blank" style="color:#2a7ce0">PDF</a>]
        [<a href="https://github.com/JinXins/SUMix" target="_blank" style="color:#2a7ce0">Code</a>]
        [<a href="./assets/poster/SUMix_poster.pdf" target="_blank" style="color:#2a7ce0">Poster</a>]
        [<a href="./assets/bibtex/ECCV_2024_SUMix_bibtex" target="_blank" style="color:#2a7ce0">BibTeX</a>]</span>
</p></td></tr>
</table>

<!-- Adversarial AutoMixup -->
<table class="imgtable"><tr><td class="table-row" style="width:220px;height:130px">
    <img src="./assets/img/AdAutoMix.jpg" alt="" />&nbsp;</td>
    <td align="left"><p>
        <font face="Lato"><b><a target="_blank" style="color:#2a7ce0">Adversarial AutoMixup</a></b></font><br>
        Huafeng Qin<sup>*,‚Ä†</sup>, <b>Xin Jin</b><sup>*</sup>, Yun Jiang, Mounim A. El-Yacoubi, Xinbo Gao
        <br><span class="pub-info"><i><b>ICLR</b>, 2024 <b>(<font color="#FF0000">Spotlight</font>)</b></i> 
        [<a href="https://arxiv.org/abs/2312.11954" target="_blank" style="color:#2a7ce0">PDF</a>]
        [<a href="https://github.com/JinXins/Adversarial-AutoMixup" target="_blank" style="color:#2a7ce0">Code</a>]
        [<a href="./assets/poster/AdAutoMix_poster_v2.pdf" target="_blank" style="color:#2a7ce0">Poster</a>]
        [<a href="./assets/bibtex/ICLR_2024_AdAutoMix_bibtex" target="_blank" style="color:#2a7ce0">BibTeX</a>]</span>
</p></td></tr>
</table>

**Journals (*: Equal Contribution. ‚Ä†: Corresponding Author.):**

<!-- EM-DARTS: Hierarchical Differentiable Architecture Search for Eye Movement Recognition -->
<table class="imgtable"><tr><td style="width:220px;height:130px">
    <img src="./assets/img/EM-DARTS.png" alt="" />&nbsp;</td>
    <td align="left"><p>
        <font face="Lato"><b><a target="_blank" style="color:#2a7ce0">EM-DARTS: Hierarchical Differentiable Architecture Search for Eye Movement Recognition</a></b></font><br>
        Huafeng Qin, Hongyu Zhu, <b>Xin Jin</b>, Xin Yu, Mounim A. El-Yacoubi, and Shuqiang Yang 
        <br><span class="pub-info"><i>IEEE TIM, 2025</i> 
        [<a href="https://ieeexplore.ieee.org/abstract/document/10919128/" target="_blank" style="color:#2a7ce0">PDF</a>]
        [<a href="./assets/bibtex/TIM_2025_EM-DARTS_bibtex" target="_blank" style="color:#2a7ce0">BibTeX</a>]</span>
</p></td></tr>
</table>

<!-- EmMixformer: Mix Transformer for Eye Movement Recognition -->
<table class="imgtable"><tr><td style="width:220px;height:130px">
    <img src="./assets/img/EmMixFomer.jpg" alt="" />&nbsp;</td>
    <td align="left"><p>
        <font face="Lato"><b><a target="_blank" style="color:#2a7ce0">EmMixformer: Mix Transformer for Eye Movement Recognition</a></b></font><br>
        Huafeng Qin, Hongyu Zhu, <b>Xin Jin</b>, Qun Song, Mounim A. El-Yacoubi, and <i>IEEE Fellow</i> Xinbo Gao 
        <br><span class="pub-info"><i>IEEE TIM, 2025</i> 
        [<a href="https://arxiv.org/abs/2401.04956" target="_blank" style="color:#2a7ce0">PDF</a>]
        [<a href="https://github.com/zzx734570533/CTBU-EMglasses-database" target="_blank" style="color:#2a7ce0">Database</a>]
        [<a href="./assets/bibtex/TIM_2025_EMMixFomer_bibtex" target="_blank" style="color:#2a7ce0">BibTeX</a>]</span>
</p></td></tr>
</table>

### Services üß∏
 - **Conference Reviewer:**  
ICLR (2025-2026), CVPR (2026), ICML (2026), ECCV (2026)
 - **Journal Reviewer:**  
Pattern Recognition.
 - **Membership**  
2024 - 2025 Student Member of IEEE  
2024 - 2025 Member of China Computer Federation (CCF)

### Awards üèÜ 
 - Academic Progress Award, CTBU, 2023
 - Challenge Cup of "Qin Chuang Yuan", National 2nd prize, 2024
 - The 14th Challenge Cup, Provincial 2nd prize, 2024
 - China International Student Innovation Competition, Provincial 2nd prize, 2024
 - The 7th Art Exhibition for College Students in Chongqing, Provincial 1st prize, 2023


### Interests üìù 
Photography. You could see some photos on <a href="https://500px.com.cn/XinJin">500px website</a> (Long time without update...)


<div style="display:flex; justify-content:center; margin-top: 10px;">
  <a href="https://clustrmaps.com/site/1c5jf" title="Visit tracker">
    <img src="https://clustrmaps.com/map_v2.png?d=hE2JchuqjgQG16sein5j0oSFN-cTW3oSbw2SrRd-czo&cl=ffffff&w=300" alt="Visitor map">
  </a>
</div>